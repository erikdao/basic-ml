{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "japanese-compound",
   "metadata": {},
   "source": [
    "# Perceptron learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "objective-statement",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "np.random.seed(2021)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "contained-israel",
   "metadata": {},
   "source": [
    "## 1. Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "purple-venice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron(inputs, weights, theta=0.):\n",
    "    \"\"\"Simple forward to a perceptron\"\"\"\n",
    "    activations = np.dot(inputs, weights)\n",
    "    \n",
    "    return np.where(activations > theta, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "breathing-college",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perceptron_train(inputs, targets, eta=0.25, n_iter=10):\n",
    "    \"\"\"Simple algorithm to train a perceptron\"\"\"\n",
    "\n",
    "    N = np.shape(inputs)[0]  # number of data points\n",
    "    n_in = np.shape(inputs)[1]  # input dimension\n",
    "    n_out = np.shape(targets)[1]  # output dimension\n",
    "    \n",
    "    # Add one more columns to the inputs for bias\n",
    "    inputs = np.concatenate((inputs,-np.ones((N,1))),axis=1)\n",
    "    # Initialize the weights\n",
    "    weights = np.random.rand(n_in + 1, n_out) * 0.1 - 0.05\n",
    "        \n",
    "    # Run the training loop\n",
    "    for i in range(n_iter):\n",
    "        # forward the inputs\n",
    "        activations = perceptron(inputs, weights)\n",
    "        print(f'Iter {i}', activations)\n",
    "        # update the weights\n",
    "        weights = weights - eta * np.dot(np.transpose(inputs), activations - targets)\n",
    "    \n",
    "    return weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-limit",
   "metadata": {},
   "source": [
    "Test the program with some artificial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "automatic-broadcast",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "targets = np.array([[0], [1], [1], [1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-version",
   "metadata": {},
   "source": [
    "Invoke the training to get the weights of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "square-jenny",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0 [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Iter 1 [[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n",
      "Iter 2 [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Iter 3 [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Iter 4 [[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n",
      "Iter 5 [[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.21059783],\n",
       "       [0.22333694],\n",
       "       [0.06389472]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W = perceptron_train(inputs, targets, eta=0.1, n_iter=6)\n",
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noticed-integration",
   "metadata": {},
   "source": [
    "**Test with the training data to see we get the correct targets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "compatible-sheffield",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add the input that match the bias node\n",
    "input_bias = np.concatenate((inputs, -np.ones((np.shape(inputs)[0], 1))), axis=1)\n",
    "perceptron(input_bias, W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "desperate-factory",
   "metadata": {},
   "source": [
    "Visualize the **decision boundary** learn by the perceptron from those data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "considered-utility",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(5, 5))\n",
    "ax.set_xlim(-0.5, 1.5)\n",
    "ax.set_ylim(-0.5, 1.5)\n",
    "\n",
    "# Plot the axis\n",
    "plt.arrow(0, 0, 0, 1.3, head_width=0.05, head_length=0.05, fc='black')\n",
    "plt.arrow(0, 0, 1.3, 0, head_width=0.05, head_length=0.05, fc='black')\n",
    "\n",
    "for idx, x in enumerate(inputs):\n",
    "    color = 'b' if targets[idx][0] == 1 else 'r'\n",
    "    plt.scatter(x=x[0], y=x[1], s=100, c=color)\n",
    "\n",
    "# helper function\n",
    "def get_x2(x1):\n",
    "    return -(W[0]*x1 - W[2]) / W[1]\n",
    "\n",
    "p1 = (-0.25, get_x2(-0.25))\n",
    "p2 = (0.5, get_x2(0.5))\n",
    "ax.plot([p1[0], p2[0]], [p1[1], p2[1]], '-', c='g', linewidth=2)\n",
    "ax.axis('off')\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
